{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3 - Reconocimiento de patrones en Minería de datos\n",
    "\n",
    "## Integrantes\n",
    "\n",
    "|Nombre | Rol|\n",
    "|:------|:---|\n",
    "|Felipe Avaria| 2923547-3|\n",
    "|Rolando Casanueva| 201204505-3|\n",
    "\n",
    "\n",
    "## Desarrollo\n",
    "\n",
    "### Información previa\n",
    "\n",
    "- Descripción de Apache Spark y MLlib\n",
    "\n",
    "**Apache spark** es una herramienta rápida y genérica para el procesamientos de datos a gran escala *Big Data*. Provee una **API** de alto nivel en distintos lenguages, tales como *Java*, *Scala*, *Python* y *R* y además incluye un sistema optimizado para ejecuciones de gráficos. También soporta herramientas como SQL tanto en estructura como procesamiento, a la vez, posee MLlib para máquinas de aprendizaje, GraphX para procesamiento de gráficos y Spark Streaming. Por otra parte **MLlib** como se mencionó, está enfocado en máquinas de aprendizaje. Esta contiene una gran variedad de algoritmos para clasificación, regresión, recomendación, clustering entre otros. Y como en esta tarea realizaremos un sistema recomendador, podemos notar como la seccions de recomendación que incluye *ALS* (Alternating least squares) está presente, será nuestra guía. [Documentación PySpark MLlib](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html)\n",
    "\n",
    "\n",
    "\n",
    "- ¿Qué son los RDD y Dataframe?\n",
    "\n",
    "**RDD** (Resilient Distributed Dataset) es una abstracción básica de Spark, la cual representa una colección de elementos inmutables y particionados que puede ser operados de manera paralela. Mientras que **Dataframe**, es una colección de elementos agrupados bajo nombres de columnas. Este últimos se maneja mediantes un *SQLContext* dadas las caracteristicas del mismo. Ambos son agrupaciones de elementos pero sus estructuras los diferencian.\n",
    "\n",
    "\n",
    "- Descripción del dataset utilizado.\n",
    "\n",
    "Como se menciona en el readme inicial del repositorio. El dataset puede ser descargado en [este link](https://grouplens.org/datasets/movielens/10m/) y dado que utilizaremos un método de *Machine Learning*, es conveniente dividir el archivo `rating`, para esto deberemos correr\n",
    "```\n",
    "c:\\PATH\\TO\\DATASET\\ bash split_ratings.sh\n",
    "```\n",
    "\n",
    "#### Formato\n",
    "\n",
    "La estructura de los archivos son las siguiente, *notar que los archivos divididos de rating tendrán el mismo formato que el original*\n",
    "\n",
    "| Dataset Name | Structure |\n",
    "| :----------- | :-------- |\n",
    "| RATINGS      |`UserID::MovieID::Rating::Timestamp` |\n",
    "| TAGS         |`UserID::MovieID::Tag::Timestamp`    |\n",
    "| MOVIES       |`MovieID::Title::Genres`             |\n",
    "\n",
    "\n",
    "#### Descripciones\n",
    "|Parámetro | Descripción|\n",
    "|:-|:-|\n",
    "|UserID | número identificador del usuario. |\n",
    "|MovieID | número identificador de la película. |\n",
    "|Rating | calificación 1 a 5 entregada por el usuario a la película. |\n",
    "|Timestamp | valor númerico del tiempo cuando se realizo la calificación.|\n",
    "|Title | titulo de la pelicula. |\n",
    "|Genres| genero de la pelicula|\n",
    "\n",
    "| Nombres de | Generos |  |\n",
    "| :------------ |:-|:-|\n",
    "|Action|Adventure|Animation|\n",
    "|Children's|Comedy|Crime|\n",
    "|Documentary|Drama|Fantasy|\n",
    "|Film-Noir|Horror|Musical|\n",
    "|Mystery|Romance|Sci-Fi|\n",
    "|Thriller|War|Western|\n",
    "\n",
    "\n",
    "----------------------\n",
    "\n",
    "### Análisis de resultados\n",
    "\n",
    "Nosotros utilizamos **Python - PySpark**, de lo que utilizamos una carga de datos **RDD**. Luego por medio del algoritmo *ALS*, entrenamos con los conjuntos de entrenamiento `rX.train` donde `x = [1, 2, 3, 4, 5]` estos entrenamientos fueron con 10 configuraciones distintas variando `rank` y `lambda_`\n",
    "\n",
    "```python\n",
    "ranks = [1, 5, 10, 50, 100]\n",
    "lambdas = [0.01, 0.02]\n",
    "model.train(data, rank, lambda_)\n",
    "```\n",
    "\n",
    "Luego a estos modelos se les solicitó predecir mediante el conjunto de valores `rX.test`. De donde los valores predichos se comparan con los reales y se genera un **RMSE** (Error  cuadrático medio) ([más info](https://es.wikipedia.org/wiki/Error_cuadr%C3%A1tico_medio)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
